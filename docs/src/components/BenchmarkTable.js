import React from 'react';
import ModelTable from './ModelTable';

const columns = [
    { Header: 'Model', accessor: 'model' },
    { Header: 'Function Calling', accessor: 'functionCalling' },
    { Header: 'MMLU (5-shot)', accessor: 'mmlu' },
    { Header: 'GPQA (0-shot)', accessor: 'gpqa' },
    { Header: 'GSM-8K (8-shot, CoT)', accessor: 'gsm8k' },
    { Header: 'MATH (4-shot, CoT)', accessor: 'math' },
    { Header: 'MT-bench', accessor: 'mtBench' },
];

const data = [
    {
        model: 'Gemma-1.1 2B Instruct',
        functionCalling: '-',
        mmlu: '37.84',
        gpqa: '22.99',
        gsm8k: '6.29',
        math: '6.14',
        mtBench: '5.82',
    },
    {
        model: 'Rubra Gemma-1.1 2B Instruct',
        functionCalling: '42.85%',
        mmlu: '38.85',
        gpqa: '24.55',
        gsm8k: '6.14',
        math: '2.38',
        mtBench: '5.75',
    },
    {
        model: 'Llama-3 8B Instruct',
        functionCalling: '-',
        mmlu: '65.69',
        gpqa: '31.47',
        gsm8k: '77.41',
        math: '27.58',
        mtBench: '8.07',
    },
    {
        model: 'Rubra Llama-3 8B Instruct',
        functionCalling: '80.92%',
        mmlu: '64.39',
        gpqa: '31.70',
        gsm8k: '68.99',
        math: '23.76',
        mtBench: '8.03',
    },
    {
        model: 'Mistral 7B Instruct v0.3',
        functionCalling: '22.5%',
        mmlu: '62.10',
        gpqa: '30.58',
        gsm8k: '53.07',
        math: '12.98',
        mtBench: '7.50',
    },
    {
        model: 'Rubra Mistral 7B Instruct v0.3',
        functionCalling: '71.42%',
        mmlu: '59.12',
        gpqa: '29.91',
        gsm8k: '43.29',
        math: '11.14',
        mtBench: '7.69',
    },
    {
        model: 'Mistral 7B Instruct v0.2',
        functionCalling: '-',
        mmlu: '59.27',
        gpqa: '27.68',
        gsm8k: '43.21',
        math: '10.30',
        mtBench: '7.50',
    },
    {
        model: 'Rubra Mistral 7B Instruct v0.2',
        functionCalling: '69.28%',
        mmlu: '58.90',
        gpqa: '29.91',
        gsm8k: '34.12',
        math: '8.36',
        mtBench: '7.36',
    },
    {
        model: 'Phi-3 Mini 128k Instruct',
        functionCalling: '-',
        mmlu: '68.17',
        gpqa: '30.58',
        gsm8k: '80.44',
        math: '28.12',
        mtBench: '7.92',
    },
    {
        model: 'Rubra Phi-3 Mini 128k Instruct',
        functionCalling: '63.57%',
        mmlu: '66.66',
        gpqa: '29.24',
        gsm8k: '74.09',
        math: '26.84',
        mtBench: '7.45',
    },
    {
        model: 'Qwen2-7B-Instruct',
        functionCalling: '-',
        mmlu: '70.78',
        gpqa: '32.14',
        gsm8k: '78.54',
        math: '30.10',
        mtBench: '8.29',
    },
    {
        model: 'Rubra Qwen2-7B-Instruct',
        functionCalling: '83.57%',
        mmlu: '68.88',
        gpqa: '30.36',
        gsm8k: '75.82',
        math: '28.72',
        mtBench: '8.08',
    },
    {
        model: 'Nexusflow/NexusRaven-V2-13B',
        functionCalling: '53.75%',
        mmlu: '-',
        gpqa: '-',
        gsm8k: '-',
        math: '-',
        mtBench:'-',
    },
    {
        model: 'NousResearch/Hermes-2-Pro-Llama-3-8B',
        functionCalling: '41.25%',
        mmlu: '-',
        gpqa: '-',
        gsm8k: '-',
        math: '-',
        mtBench:'-',
    },
    {
        model: 'gorilla-llm/gorilla-openfunctions-v2',
        functionCalling: '41.25%',
        mmlu: '-',
        gpqa: '-',
        gsm8k: '-',
        math: '-',
        mtBench:'-',
    },
    {
        model: 'GPT-4o',
        functionCalling: '98.57%',
        mmlu: '-',
        gpqa: '-',
        gsm8k: '-',
        math: '-',
        mtBench:'-',
    },
    {
        model: 'Claude-3.5 Sonnet',
        functionCalling: '98.57%',
        mmlu: '-',
        gpqa: '-',
        gsm8k: '-',
        math: '-',
        mtBench:'-',
    }
];

function BenchmarkTable() {
    return <ModelTable columns={columns} data={data} />;
}

export default BenchmarkTable;
